{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da557139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "project_root = os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\")))\n",
    "\n",
    "import pandas as pd\n",
    "from training import TrainingManager, TrainingConfig\n",
    "from envs.trading_env import MyTradingEnv\n",
    "\n",
    "N_EPISODES_END=15_000\n",
    "\n",
    "N_EPISODES_START=10_000\n",
    "\n",
    "MAX_STEPS=1_000\n",
    "LEARNING_RATE=0.05\n",
    "DISCOUNT_FACTOR=0.9\n",
    "EPSILON_START=1.0\n",
    "EPSILON_END=0.05\n",
    "EPSILON_DECAY=0.9995\n",
    "EVAL_FREQUANCY=200\n",
    "SAVE_FREQUANCY=1_000\n",
    "\n",
    "TRAIN_VERSION=\"v1\"\n",
    "\n",
    "data_path = \"../data/data_1h_2021.csv\"\n",
    "df1 = pd.read_csv(data_path, index_col=0, parse_dates=True, date_format=\"iso8601\")\n",
    "data_path = \"../data/data_1h_2022.csv\"\n",
    "df2 = pd.read_csv(data_path, index_col=0, parse_dates=True, date_format=\"iso8601\")\n",
    "data_path = \"../data/data_1h_2023.csv\"\n",
    "df3 = pd.read_csv(data_path, index_col=0, parse_dates=True, date_format=\"iso8601\")\n",
    "\n",
    "df = pd.concat([df1])\n",
    "\n",
    "INITIAL_BALANCE = 1000.0\n",
    "WINDOW_SIZE = 10\n",
    "COMMISSION = 0.0001\n",
    "SLIPPAGE = 0.0005\n",
    "MAX_HOLDING_TIME = 60 * 24\n",
    "HOLDING_THRESHOLD = 24\n",
    "MAX_DRAWDOWN_THRESHOLD = 0.05\n",
    "LAMBDA_DRAWDOWN = 0.1\n",
    "LAMBDA_HOLD = 0.01\n",
    "REWARD_SCALING=10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eef98352",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_params = {\n",
    "    \"initial_balance\": INITIAL_BALANCE,\n",
    "    \"window_size\": WINDOW_SIZE,\n",
    "    \"commission\": COMMISSION,\n",
    "    \"slippage\": SLIPPAGE,\n",
    "    \"max_holding_time\": MAX_HOLDING_TIME,\n",
    "    \"lambda_drawdown\": LAMBDA_DRAWDOWN,\n",
    "    \"lambda_hold\": LAMBDA_HOLD,\n",
    "    \"reward_scaling\": REWARD_SCALING,\n",
    "    \"max_steps\": MAX_STEPS,\n",
    "}\n",
    "\n",
    "continue_train_params = {\n",
    "    \"n_episodes\": N_EPISODES_END,\n",
    "    \"n_episodes_start\": N_EPISODES_START,\n",
    "    \"max_steps\": MAX_STEPS,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"discount_factor\": DISCOUNT_FACTOR,\n",
    "    \"epsilon_start\": EPSILON_START,\n",
    "    \"epsilon_end\": EPSILON_END,\n",
    "    \"epsilon_decay\": EPSILON_DECAY,\n",
    "    \"eval_frequency\": EVAL_FREQUANCY,\n",
    "    \"save_frequency\": SAVE_FREQUANCY,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd6c6cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_continue_training(\n",
    "    agent_type: str,\n",
    "    df,\n",
    "    project_root: str,\n",
    "    env_params: dict,\n",
    "    train_params: dict,\n",
    "    train_version: str,\n",
    "):\n",
    "    if agent_type == \"SARSA\":\n",
    "        from agents.classical.sarsa_agent import SarsaAgent\n",
    "\n",
    "        agent = SarsaAgent()\n",
    "\n",
    "    elif agent_type == \"SARSA_Lambda\":\n",
    "        from agents.classical.sarsa_lambda_agent import SarsaLambdaAgent\n",
    "\n",
    "        agent = SarsaLambdaAgent()\n",
    "\n",
    "    elif agent_type == \"QLearning\":\n",
    "        from agents.classical.qlearning_agent import QLearningAgent\n",
    "\n",
    "        agent = QLearningAgent()\n",
    "\n",
    "    elif agent_type == \"Monte_Carlo\":\n",
    "        from agents.classical.monte_carlo_agent import MonteCarloAgent\n",
    "\n",
    "        agent = MonteCarloAgent()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown agent type: {agent_type}\")\n",
    "\n",
    "    checkpoint_path = os.path.join(\n",
    "        project_root,\n",
    "        \"training_data\",\n",
    "        \"checkpoints\",\n",
    "        f\"exp_{agent_type.lower()}_{train_version}\",\n",
    "        \"final_agent.pkl\",\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "\n",
    "    env = MyTradingEnv(df=df, **env_params)\n",
    "\n",
    "    continue_config = TrainingConfig(\n",
    "        agent_name=f\"{agent_type}_{train_version}_continue\",\n",
    "        agent_type=agent_type,\n",
    "        **train_params,\n",
    "    )\n",
    "\n",
    "    manager = TrainingManager(\n",
    "        base_log_dir=os.path.join(project_root, \"training_data/logs\"),\n",
    "        base_checkpoint_dir=os.path.join(project_root, \"training_data/checkpoints\"),\n",
    "    )\n",
    "\n",
    "    experiment_name = f\"exp_{agent_type.lower()}_{train_version}_continue\"\n",
    "\n",
    "    return manager.continue_training(\n",
    "        agent=agent,\n",
    "        env=env,\n",
    "        config=continue_config,\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        experiment_name=experiment_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028a6daf",
   "metadata": {},
   "source": [
    "### Дообучение QLearningAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "313edafd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainingConfig.__init__() got an unexpected keyword argument 'agent_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results_qlearning = \u001b[43mrun_continue_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mQLearning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_root\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject_root\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43menv_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontinue_train_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTRAIN_VERSION\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mrun_continue_training\u001b[39m\u001b[34m(agent_type, df, project_root, env_params, train_params, train_version)\u001b[39m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCheckpoint not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m env = MyTradingEnv(df=df, **env_params)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m continue_config = \u001b[43mTrainingConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43magent_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtrain_version\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_continue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43magent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m manager = TrainingManager(\n\u001b[32m     52\u001b[39m     base_log_dir=os.path.join(project_root, \u001b[33m\"\u001b[39m\u001b[33mtraining_data/logs\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     53\u001b[39m     base_checkpoint_dir=os.path.join(project_root, \u001b[33m\"\u001b[39m\u001b[33mtraining_data/checkpoints\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     54\u001b[39m )\n\u001b[32m     56\u001b[39m experiment_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexp_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_type.lower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_continue\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: TrainingConfig.__init__() got an unexpected keyword argument 'agent_type'"
     ]
    }
   ],
   "source": [
    "results_qlearning = run_continue_training(\n",
    "    agent_type=\"QLearning\",\n",
    "    df=df,\n",
    "    project_root=project_root,\n",
    "    env_params=env_params,\n",
    "    train_params=continue_train_params,\n",
    "    train_version=TRAIN_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49719c20",
   "metadata": {},
   "source": [
    "### Дообучение MonteCarloAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff4a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue_train_params[\"max_steps\"] = MAX_STEPS // 2\n",
    "\n",
    "results_montecarlo = run_continue_training(\n",
    "    agent_type=\"Monte_Carlo\",\n",
    "    df=df,\n",
    "    project_root=project_root,\n",
    "    env_params=env_params,\n",
    "    train_params=continue_train_params,\n",
    "    train_version=TRAIN_VERSION\n",
    ")\n",
    "# continue_train_params[\"max_steps\"] = MAX_STEPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578305dd",
   "metadata": {},
   "source": [
    "### Дообучение SARSAAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5459ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sarsa = run_continue_training(\n",
    "    agent_type=\"SARSA\",\n",
    "    df=df,\n",
    "    project_root=project_root,\n",
    "    env_params=env_params,\n",
    "    train_params=continue_train_params,\n",
    "    train_version=TRAIN_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc1e68f",
   "metadata": {},
   "source": [
    "### Дообучение SARSALambdaAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a993889",
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_train_params_lambda = {\n",
    "    **continue_train_params,\n",
    "    \"lambda_param\": 0.8,\n",
    "}\n",
    "\n",
    "results_sarsalambda = run_continue_training(\n",
    "    agent_type=\"SARSA_Lambda\",\n",
    "    df=df,\n",
    "    project_root=project_root,\n",
    "    env_params=env_params,\n",
    "    train_params=continue_train_params_lambda,\n",
    "    train_version=TRAIN_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced56c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "experiment_dirs = [\n",
    "    f\"../training_data/logs/exp_qlearning_{TRAIN_VERSION}_continue\",\n",
    "    f\"../training_data/logs/exp_monte_carlo_{TRAIN_VERSION}_continue\",\n",
    "    f\"../training_data/logs/exp_sarsa_{TRAIN_VERSION}_continue\",\n",
    "    f\"../training_data/logs/exp_sarsa_lambda_{TRAIN_VERSION}_continue\",\n",
    "]\n",
    "\n",
    "all_data = []\n",
    "for exp_dir in experiment_dirs:\n",
    "    exp_dir = Path(exp_dir)\n",
    "    episodes_df = pd.read_csv(exp_dir / \"episodes.csv\")\n",
    "    with open(exp_dir / \"training_summary.json\") as f:\n",
    "        summary = json.load(f)\n",
    "    agent_name = summary[\"config\"][\"agent_name\"]\n",
    "    episodes_df[\"agent\"] = agent_name\n",
    "    all_data.append(episodes_df)\n",
    "\n",
    "\n",
    "df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for agent in df[\"agent\"].unique():\n",
    "    agent_data = df[df[\"agent\"] == agent]\n",
    "    smoothed = agent_data[\"reward\"].rolling(window=50, min_periods=1).mean()\n",
    "    plt.plot(agent_data[\"episode\"], smoothed, label=agent)\n",
    "\n",
    "plt.title(\"Сравнение средней награды (скользящее окно = 50)\")\n",
    "plt.xlabel(\"Эпизод\")\n",
    "plt.ylabel(\"Награда (сглаженная)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for agent in df[\"agent\"].unique():\n",
    "    agent_data = df[df[\"agent\"] == agent]\n",
    "    plt.plot(agent_data[\"episode\"], agent_data[\"portfolio_value\"], label=agent)\n",
    "\n",
    "plt.title(\"Динамика стоимости портфеля\")\n",
    "plt.xlabel(\"Эпизод\")\n",
    "plt.ylabel(\"Portfolio Value ($)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "final_metrics = df.groupby(\"agent\").tail(1)[\n",
    "    [\"agent\", \"reward\", \"portfolio_value\", \"win_rate\", \"n_trades\", \"max_drawdown\"]\n",
    "]\n",
    "display(final_metrics.round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
