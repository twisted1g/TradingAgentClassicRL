{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c9a47178",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Данные для дообучения: 8722 строк\n",
            "Период: 28966.36 - 47558.35\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "current_dir = Path.cwd()\n",
        "if current_dir.name == \"notebooks\":\n",
        "    project_root = current_dir.parent\n",
        "    sys.path.insert(0, str(project_root))\n",
        "else:\n",
        "    project_root = Path(os.getcwd())\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "import pandas as pd\n",
        "from training import TrainingManager, TrainingConfig\n",
        "\n",
        "TRAIN_VERSION = \"v2\"\n",
        "N_EPISODES_INITIAL = 100\n",
        "N_EPISODES_FINETUNE = 500\n",
        "N_EPISODES_START_FINETUNE = N_EPISODES_INITIAL\n",
        "N_EPISODES_END_FINETUNE = N_EPISODES_INITIAL + N_EPISODES_FINETUNE\n",
        "\n",
        "\n",
        "data_path_2021 = project_root / \"data\" / \"data_1h_2021.csv\"\n",
        "data_path_2022 = project_root / \"data\" / \"data_1h_2022.csv\"\n",
        "data_path_2023 = project_root / \"data\" / \"data_1h_2023.csv\"\n",
        "\n",
        "if not data_path_2021.exists():\n",
        "    data_path_2021 = project_root.parent / \"data\" / \"data_1h_2021.csv\"\n",
        "    data_path_2022 = project_root.parent / \"data\" / \"data_1h_2022.csv\"\n",
        "    data_path_2023 = project_root.parent / \"data\" / \"data_1h_2023.csv\"\n",
        "\n",
        "df1 = pd.read_csv(data_path_2021, index_col=0, parse_dates=True, date_format=\"iso8601\")\n",
        "df2 = pd.read_csv(data_path_2022, index_col=0, parse_dates=True, date_format=\"iso8601\")\n",
        "df3 = (\n",
        "    pd.read_csv(data_path_2023, index_col=0, parse_dates=True, date_format=\"iso8601\")\n",
        "    if data_path_2023.exists()\n",
        "    else None\n",
        ")\n",
        "\n",
        "\n",
        "# df_train = pd.concat([df1, df2.iloc[: len(df2) // 2]])\n",
        "\n",
        "\n",
        "# if df3 is not None:\n",
        "#     df_finetune = pd.concat([df2.iloc[len(df2)//2:], df3])\n",
        "# else:\n",
        "# df_finetune = df2.iloc[len(df2) // 2 :]\n",
        "\n",
        "df_finetune = pd.concat([df1])\n",
        "\n",
        "print(f\"Данные для дообучения: {len(df_finetune)} строк\")\n",
        "print(f\"Период: {df_finetune.index[0]} - {df_finetune.index[-1]}\")\n",
        "\n",
        "\n",
        "env_params = {\n",
        "    \"initial_balance\": 1000.0,\n",
        "    \"window_size\": 10,\n",
        "    \"commission\": 0.0001,\n",
        "    \"slippage\": 0.0001,\n",
        "    \"max_holding_time\": 72,\n",
        "    \"max_drawdown_threshold\": 0.08,\n",
        "    \"max_steps\": 1000,\n",
        "}\n",
        "\n",
        "\n",
        "base_train_params = {\n",
        "    \"n_episodes\": N_EPISODES_INITIAL,\n",
        "    \"n_episodes_start\": 0,\n",
        "    \"max_steps\": 1000,\n",
        "    \"eval_frequency\": 100,\n",
        "    \"save_frequency\": 500,\n",
        "    \"patience\": 200,\n",
        "    \"initial_balance\": 1000.0,\n",
        "    **{k: env_params[k] for k in env_params if k != \"max_steps\"},\n",
        "}\n",
        "\n",
        "\n",
        "finetune_train_params = {\n",
        "    \"n_episodes\": N_EPISODES_END_FINETUNE,\n",
        "    \"n_episodes_start\": N_EPISODES_START_FINETUNE,\n",
        "    \"max_steps\": 1000,\n",
        "    \"eval_frequency\": 50,\n",
        "    \"save_frequency\": 500,\n",
        "    \"patience\": 200,\n",
        "    \"initial_balance\": 1000.0,\n",
        "    **{k: env_params[k] for k in env_params if k != \"max_steps\"},\n",
        "}\n",
        "\n",
        "\n",
        "agents_config = {\n",
        "    \"QLearning\": {\n",
        "        \"learning_rate\": 0.05,\n",
        "        \"discount_factor\": 0.99,\n",
        "        \"epsilon_start\": 1.0,\n",
        "        \"epsilon_end\": 0.01,\n",
        "        \"epsilon_decay\": 0.998,\n",
        "    },\n",
        "    \"SARSA\": {\n",
        "        \"learning_rate\": 0.05,\n",
        "        \"discount_factor\": 0.99,\n",
        "        \"epsilon_start\": 1.0,\n",
        "        \"epsilon_end\": 0.01,\n",
        "        \"epsilon_decay\": 0.998,\n",
        "    },\n",
        "    \"SARSA_Lambda\": {\n",
        "        \"learning_rate\": 0.02,\n",
        "        \"discount_factor\": 0.99,\n",
        "        \"epsilon_start\": 1.0,\n",
        "        \"epsilon_end\": 0.01,\n",
        "        \"epsilon_decay\": 0.998,\n",
        "        \"trace_decay\": 0.9,\n",
        "    },\n",
        "    \"Monte_Carlo\": {\n",
        "        \"learning_rate\": 0.02,\n",
        "        \"discount_factor\": 0.99,\n",
        "        \"epsilon_start\": 1.0,\n",
        "        \"epsilon_end\": 0.05,\n",
        "        \"epsilon_decay\": 0.999,\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "def _get_agent_instance(agent_type: str, hyperparams: dict):\n",
        "    if agent_type == \"SARSA\":\n",
        "        from agents.classical.sarsa_agent import SarsaAgent\n",
        "\n",
        "        agent = SarsaAgent()\n",
        "    elif agent_type == \"SARSA_Lambda\":\n",
        "        from agents.classical.sarsa_lambda_agent import SarsaLambdaAgent\n",
        "\n",
        "        agent = SarsaLambdaAgent()\n",
        "    elif agent_type == \"QLearning\":\n",
        "        from agents.classical.qlearning_agent import QLearningAgent\n",
        "\n",
        "        agent = QLearningAgent()\n",
        "    elif agent_type == \"Monte_Carlo\":\n",
        "        from agents.classical.monte_carlo_agent import MonteCarloAgent\n",
        "\n",
        "        agent = MonteCarloAgent()\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown agent type: {agent_type}\")\n",
        "\n",
        "    for key, value in hyperparams.items():\n",
        "        if hasattr(agent, key):\n",
        "            setattr(agent, key, value)\n",
        "    return agent\n",
        "\n",
        "\n",
        "def run_finetuning(\n",
        "    agent_type: str,\n",
        "    df,\n",
        "    project_root: str,\n",
        "    env_params: dict,\n",
        "    train_params: dict,\n",
        "):\n",
        "    hyperparams = agents_config.get(agent_type, {})\n",
        "\n",
        "    experiment_name_base = f\"exp_{agent_type.lower()}_{TRAIN_VERSION}\"\n",
        "    experiment_name_finetune = f\"{experiment_name_base}_finetune\"\n",
        "\n",
        "    checkpoint_path = os.path.join(\n",
        "        project_root,\n",
        "        \"training_data\",\n",
        "        \"checkpoints\",\n",
        "        experiment_name_base,\n",
        "        \"final_agent.pkl\",\n",
        "    )\n",
        "\n",
        "    if not Path(checkpoint_path).exists():\n",
        "        print(f\"!!! ОШИБКА: Файл чекпоинта не найден: {checkpoint_path}\")\n",
        "        raise FileNotFoundError(\"Сначала запустите и завершите ПЕРВИЧНОЕ ОБУЧЕНИЕ.\")\n",
        "\n",
        "    agent = _get_agent_instance(agent_type, hyperparams)\n",
        "\n",
        "    continue_config = TrainingConfig(\n",
        "        agent_name=f\"{agent_type}_{TRAIN_VERSION}_finetune\",\n",
        "        agent_type=agent_type,\n",
        "        **train_params,\n",
        "    )\n",
        "\n",
        "    manager = TrainingManager(\n",
        "        base_log_dir=os.path.join(project_root, \"training_data/logs\"),\n",
        "        base_checkpoint_dir=os.path.join(project_root, \"training_data/checkpoints\"),\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=======================================================\")\n",
        "    print(\n",
        "        f\" НАЧАЛО ДООБУЧЕНИЯ: {agent_type} (Ep: {train_params['n_episodes_start']} -> {train_params['n_episodes']})\"\n",
        "    )\n",
        "    print(f\"=======================================================\")\n",
        "\n",
        "    return manager.continue_training(\n",
        "        agent=agent,\n",
        "        df=df,\n",
        "        config=continue_config,\n",
        "        checkpoint_path=checkpoint_path,\n",
        "        experiment_name=experiment_name_finetune,\n",
        "        verbose=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "23bd2ce8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=======================================================\n",
            " НАЧАЛО ДООБУЧЕНИЯ: QLearning (Ep: 100 -> 600)\n",
            "=======================================================\n",
            "\n",
            "Загрузка агента из /mnt/d/Study/Code/ml/TradingAgentClassicRL/training_data/checkpoints/exp_qlearning_v2/final_agent.pkl\n",
            "\n",
            "====================================================================================================\n",
            " НАЧАЛО ОБУЧЕНИЯ\n",
            "====================================================================================================\n",
            "Агент:          QLearning_v2_finetune\n",
            "Эксперимент:    exp_qlearning_v2_finetune\n",
            "Эпизодов:       600\n",
            "Max steps:       1000\n",
            "Learning rate:  0.1\n",
            "Discount:       0.95\n",
            "Epsilon:        1.0 → 0.01\n",
            "Eval frequency: 50\n",
            "Patience:       200\n",
            "Initial balance: $1,000.00\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "НОВАЯ ЛУЧШАЯ МОДЕЛЬ!\n",
            "   Eval Reward: -22.19\n",
            "   Portfolio: $892.89 (-10.71%)\n",
            "   Total PnL: $-83.90\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "Эпизод   150/600 [ 25.0%] |███████░░░░░░░░░░░░░░░░░░░░░░░|\n",
            "----------------------------------------------------------------------------------------------------\n",
            "НАГРАДЫ:\n",
            "   Текущая:         -43.97 | Средняя (100):     -43.97 | Eval:     -22.19 ± 22.49\n",
            "ПОРТФЕЛЬ:\n",
            "   Значение:       $892.89 | Изменение:        -10.71%\n",
            "ТОРГОВЛЯ (на основе eval):\n",
            "   Сделок:           108.4 | Win Rate:        64.5% | Profit Factor:   0.92\n",
            "   Avg PnL:      $    -0.91 | Total PnL:     $   -83.90\n",
            "ПАРАМЕТРЫ:\n",
            "   Epsilon:          0.9047 | Learning Rate:     0.0500 | States:     35\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "НОВАЯ ЛУЧШАЯ МОДЕЛЬ!\n",
            "   Eval Reward: -15.38\n",
            "   Portfolio: $922.94 (-7.71%)\n",
            "   Total PnL: $-39.79\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "Эпизод   200/600 [ 33.3%] |██████████░░░░░░░░░░░░░░░░░░░░|\n",
            "----------------------------------------------------------------------------------------------------\n",
            "НАГРАДЫ:\n",
            "   Текущая:         -14.24 | Средняя (100):     -28.64 | Eval:     -15.38 ± 23.02\n",
            "ПОРТФЕЛЬ:\n",
            "   Значение:       $922.94 | Изменение:         -7.71%\n",
            "ТОРГОВЛЯ (на основе eval):\n",
            "   Сделок:            61.0 | Win Rate:        82.4% | Profit Factor:   1.01\n",
            "   Avg PnL:      $    -0.30 | Total PnL:     $   -39.79\n",
            "ПАРАМЕТРЫ:\n",
            "   Epsilon:          0.8186 | Learning Rate:     0.0500 | States:     35\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "НОВАЯ ЛУЧШАЯ МОДЕЛЬ!\n",
            "   Eval Reward: -12.22\n",
            "   Portfolio: $936.92 (-6.31%)\n",
            "   Total PnL: $-20.24\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "Эпизод   250/600 [ 41.7%] |████████████░░░░░░░░░░░░░░░░░░|\n",
            "----------------------------------------------------------------------------------------------------\n",
            "НАГРАДЫ:\n",
            "   Текущая:         -36.10 | Средняя (100):     -28.55 | Eval:     -12.22 ± 30.75\n",
            "ПОРТФЕЛЬ:\n",
            "   Значение:       $936.92 | Изменение:         -6.31%\n",
            "ТОРГОВЛЯ (на основе eval):\n",
            "   Сделок:           100.0 | Win Rate:        65.1% | Profit Factor:   1.06\n",
            "   Avg PnL:      $    -0.34 | Total PnL:     $   -20.24\n",
            "ПАРАМЕТРЫ:\n",
            "   Epsilon:          0.7406 | Learning Rate:     0.0500 | States:     35\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "Эпизод   300/600 [ 50.0%] |███████████████░░░░░░░░░░░░░░░|\n",
            "----------------------------------------------------------------------------------------------------\n",
            "НАГРАДЫ:\n",
            "   Текущая:         -16.96 | Средняя (100):     -31.30 | Eval:     -19.97 ± 23.84\n",
            "ПОРТФЕЛЬ:\n",
            "   Значение:       $905.20 | Изменение:         -9.48%\n",
            "ТОРГОВЛЯ (на основе eval):\n",
            "   Сделок:            62.4 | Win Rate:        84.8% | Profit Factor:   0.94\n",
            "   Avg PnL:      $    -1.03 | Total PnL:     $   -76.32\n",
            "ПАРАМЕТРЫ:\n",
            "   Epsilon:          0.6701 | Learning Rate:     0.0500 | States:     36\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "Эпизод   350/600 [ 58.3%] |█████████████████░░░░░░░░░░░░░|\n",
            "----------------------------------------------------------------------------------------------------\n",
            "НАГРАДЫ:\n",
            "   Текущая:         -61.77 | Средняя (100):     -31.95 | Eval:     -18.99 ± 12.63\n",
            "ПОРТФЕЛЬ:\n",
            "   Значение:       $914.28 | Изменение:         -8.57%\n",
            "ТОРГОВЛЯ (на основе eval):\n",
            "   Сделок:            52.4 | Win Rate:        83.4% | Profit Factor:   0.91\n",
            "   Avg PnL:      $    -0.97 | Total PnL:     $   -57.74\n",
            "ПАРАМЕТРЫ:\n",
            "   Epsilon:          0.6062 | Learning Rate:     0.0500 | States:     36\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "Эпизод   400/600 [ 66.7%] |████████████████████░░░░░░░░░░|\n",
            "----------------------------------------------------------------------------------------------------\n",
            "НАГРАДЫ:\n",
            "   Текущая:         -44.12 | Средняя (100):     -30.74 | Eval:     -20.23 ± 23.86\n",
            "ПОРТФЕЛЬ:\n",
            "   Значение:       $903.77 | Изменение:         -9.62%\n",
            "ТОРГОВЛЯ (на основе eval):\n",
            "   Сделок:            60.6 | Win Rate:        84.1% | Profit Factor:   0.94\n",
            "   Avg PnL:      $    -1.03 | Total PnL:     $   -77.95\n",
            "ПАРАМЕТРЫ:\n",
            "   Epsilon:          0.5485 | Learning Rate:     0.0500 | States:     36\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "Эпизод   450/600 [ 75.0%] |██████████████████████░░░░░░░░|\n",
            "----------------------------------------------------------------------------------------------------\n",
            "НАГРАДЫ:\n",
            "   Текущая:         +17.68 | Средняя (100):     -26.85 | Eval:     -23.45 ± 22.11\n",
            "ПОРТФЕЛЬ:\n",
            "   Значение:       $885.03 | Изменение:        -11.50%\n",
            "ТОРГОВЛЯ (на основе eval):\n",
            "   Сделок:            61.2 | Win Rate:        83.9% | Profit Factor:   0.90\n",
            "   Avg PnL:      $    -1.37 | Total PnL:     $   -96.86\n",
            "ПАРАМЕТРЫ:\n",
            "   Epsilon:          0.4962 | Learning Rate:     0.0500 | States:     36\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "Эпизод   500/600 [ 83.3%] |█████████████████████████░░░░░|\n",
            "----------------------------------------------------------------------------------------------------\n",
            "НАГРАДЫ:\n",
            "   Текущая:         -51.71 | Средняя (100):     -27.42 | Eval:     -17.54 ± 16.07\n",
            "ПОРТФЕЛЬ:\n",
            "   Значение:       $917.14 | Изменение:         -8.29%\n",
            "ТОРГОВЛЯ (на основе eval):\n",
            "   Сделок:            77.0 | Win Rate:        66.7% | Profit Factor:   0.97\n",
            "   Avg PnL:      $    -0.52 | Total PnL:     $   -50.15\n",
            "ПАРАМЕТРЫ:\n",
            "   Epsilon:          0.4490 | Learning Rate:     0.0500 | States:     36\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "Эпизод   550/600 [ 91.7%] |███████████████████████████░░░|\n",
            "----------------------------------------------------------------------------------------------------\n",
            "НАГРАДЫ:\n",
            "   Текущая:          +3.82 | Средняя (100):     -33.25 | Eval:     -28.37 ± 13.01\n",
            "ПОРТФЕЛЬ:\n",
            "   Значение:       $859.95 | Изменение:        -14.00%\n",
            "ТОРГОВЛЯ (на основе eval):\n",
            "   Сделок:            59.2 | Win Rate:        79.0% | Profit Factor:   0.84\n",
            "   Avg PnL:      $    -1.92 | Total PnL:     $  -121.77\n",
            "ПАРАМЕТРЫ:\n",
            "   Epsilon:          0.4062 | Learning Rate:     0.0500 | States:     36\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "Эпизод   600/600 [100.0%] |██████████████████████████████|\n",
            "----------------------------------------------------------------------------------------------------\n",
            "НАГРАДЫ:\n",
            "   Текущая:         -13.00 | Средняя (100):     -31.96 | Eval:     -24.50 ± 24.77\n",
            "ПОРТФЕЛЬ:\n",
            "   Значение:       $899.11 | Изменение:        -10.09%\n",
            "ТОРГОВЛЯ (на основе eval):\n",
            "   Сделок:           114.8 | Win Rate:        54.0% | Profit Factor:   0.88\n",
            "   Avg PnL:      $    -0.78 | Total PnL:     $   -86.97\n",
            "ПАРАМЕТРЫ:\n",
            "   Epsilon:          0.3675 | Learning Rate:     0.0500 | States:     36\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "ОБУЧЕНИЕ ЗАВЕРШЕНО!\n",
            "====================================================================================================\n",
            "СТАТИСТИКА ОБУЧЕНИЯ:\n",
            "   Всего эпизодов:            500\n",
            "   Время обучения:            4.81 минут\n",
            "   Лучшая eval награда:     -12.28\n",
            "   Размер Q-таблицы:           36 состояний\n",
            "   Финальный epsilon:      0.3675\n",
            "\n",
            "ФИНАЛЬНАЯ ОЦЕНКА:\n",
            "   Средняя награда:         -16.49\n",
            "   Средний портфель:    $   931.67 (-6.83%)\n",
            "   Количество сделок:        124.4\n",
            "   Средние шаги:            1000.0\n",
            "   Win Rate:                 55.1%\n",
            "   Profit Factor:            1.02\n",
            "   Avg PnL:            $    -0.44\n",
            "   Total PnL:          $   -48.88\n",
            "\n",
            "СОХРАНЕНО:\n",
            "   Логи:                /mnt/d/Study/Code/ml/TradingAgentClassicRL/training_data/logs/exp_qlearning_v2_finetune\n",
            "   Чекпойнты:           /mnt/d/Study/Code/ml/TradingAgentClassicRL/training_data/checkpoints/exp_qlearning_v2_finetune\n",
            "====================================================================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'experiment_name': 'exp_qlearning_v2_finetune',\n",
              " 'log_dir': '/mnt/d/Study/Code/ml/TradingAgentClassicRL/training_data/logs/exp_qlearning_v2_finetune',\n",
              " 'checkpoint_dir': '/mnt/d/Study/Code/ml/TradingAgentClassicRL/training_data/checkpoints/exp_qlearning_v2_finetune',\n",
              " 'final_agent_path': '/mnt/d/Study/Code/ml/TradingAgentClassicRL/training_data/checkpoints/exp_qlearning_v2_finetune/final_agent.pkl',\n",
              " 'best_agent_path': '/mnt/d/Study/Code/ml/TradingAgentClassicRL/training_data/checkpoints/exp_qlearning_v2_finetune/best_agent.pkl',\n",
              " 'training_time': 288.41730260849,\n",
              " 'best_val_reward': -12.27835568549915,\n",
              " 'final_metrics': {'episode': 600,\n",
              "  'reward': -13.002377151179433,\n",
              "  'steps': 1000,\n",
              "  'epsilon': 0.36751125485715885,\n",
              "  'portfolio_value': 1004.9803137161223,\n",
              "  'n_trades': 149,\n",
              "  'win_rate': 46.97986577181208,\n",
              "  'avg_pnl': 0.13847138681579718,\n",
              "  'max_drawdown': 0.06046289094940942,\n",
              "  'total_pnl': 20.63223663555378,\n",
              "  'timestamp': 1765801935.4057178},\n",
              " 'final_evaluation': {'mean_reward': -16.49237706917404,\n",
              "  'std_reward': 27.85171318443551,\n",
              "  'min_reward': -52.317977030774465,\n",
              "  'max_reward': 22.0816041855659,\n",
              "  'mean_portfolio': 931.6698220932745,\n",
              "  'mean_trades': 124.4,\n",
              "  'mean_steps': 1000.0,\n",
              "  'mean_total_pnl': -48.88358942363651,\n",
              "  'mean_win_rate': 55.064471750439225,\n",
              "  'mean_profit_factor': 1.0204846433334798,\n",
              "  'mean_avg_pnl': -0.4433333140168931}}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_finetuning(\n",
        "    agent_type=\"QLearning\",\n",
        "    df=df_finetune,\n",
        "    project_root=project_root,\n",
        "    env_params=env_params,\n",
        "    train_params=finetune_train_params,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "083f4662",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
